# LLM Health Advice Evaluation

This project investigates the factual accuracy and potential bias in GPT-4-generated health advice by comparing it to verified sources such as CDC and WHO.

`How factually accurate and unbiased are GPT-4â€™s responses to common mental health and wellness questions compared to information from the CDC and WHO?`

## Goals

- Evaluate how accurate GPT-4 is on common health questions
- Analyze any bias or misleading patterns
- Share insights that could improve AI safety in healthcare

## Structure

- `data/`: Raw inputs, GPT outputs, verified references, and evaluation results
- `scripts/`: Automation scripts for generating and evaluating responses
- `notebooks/`: Exploratory analysis in Jupyter
- `results/`: Visualizations and summary graphs
- `docs/`: Final writeup or blog post draft

## Getting Started

```bash
git clone https://github.com/ayobamiu/llm-health-eval.git
cd llm-health-eval
pip install -r requirements.txt
```
